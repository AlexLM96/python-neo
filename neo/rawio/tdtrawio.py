# -*- coding: utf-8 -*-
"""
Class for reading data from from Tucker Davis TTank format.
Terminology:
TDT hold data with tanks (actually a directory). And tanks hold sub block
(sub directories).
Tanks correspond to neo.Block and tdt block correspond to neo.Segment.

Note the name Block is ambiguous because it does not refer to same thing in TDT
terminology and neo.


Author: Samuel Garcia

"""
from __future__ import unicode_literals, print_function, division, absolute_import

from .baserawio import (BaseRawIO, _signal_channel_dtype, _unit_channel_dtype, 
        _event_channel_dtype)

import numpy as np
import os
import re
from collections import OrderedDict




class TdtRawIO(BaseRawIO):
    rawmode = 'one-dir'
    
    def __init__(self, dirname='', sortname=''):
        """
        'sortname' is used to specify the external sortcode generated by offline spike sorting.
        if sortname=='PLX', there should be a ./sort/PLX/*.SortResult file in the tdt block,
        which stores the sortcode for every spike; defaults to '', which uses the original online sort
        """
        BaseRawIO.__init__(self)
        self.dirname = dirname
        
        self.sortname = sortname
    
    def _source_name(self):
        return self.dirname
    
    def _parse_header(self):
        
        tankname = os.path.basename(self.dirname)
        
        segment_names = []
        for segment_name in os.listdir(self.dirname):
            path = os.path.join(self.dirname, segment_name)
            if is_tdtblock(path):
                segment_names.append(segment_name)
        
        nb_segment = len(segment_names)
        
        #TBK (channel info)
        info_channel_groups = None
        for seg_index, segment_name in enumerate(segment_names):
            path = os.path.join(self.dirname, segment_name)
            
            #TBK contain channels
            tbk_filename = os.path.join(path, tankname+'_'+segment_name+'.Tbk')
            _info_channel_groups = read_tbk(tbk_filename)
            if info_channel_groups is None:
                info_channel_groups = _info_channel_groups
            else:
                assert np.array_equal(info_channel_groups, _info_channel_groups), 'Channels differ across segments'
        
        #TEV (mixed data)
        self._tev_datas = []
        for seg_index, segment_name in enumerate(segment_names):
            path = os.path.join(self.dirname, segment_name)
            tev_filename = os.path.join(path, tankname+'_'+segment_name+'.tev')
            if os.path.exists(tev_filename):
                tev_data = np.memmap(tev_filename, mode='r', offset=0, dtype='uint8')
            else:
                tev_data = None
            self._tev_datas.append(tev_data)
        
        #TSQ index with timestamp
        
        self._tsq = []
        self._global_t_start = []
        self._global_t_stop = []
        for seg_index, segment_name in enumerate(segment_names):
            path = os.path.join(self.dirname, segment_name)
            tsq_filename = os.path.join(path, tankname+'_'+segment_name+'.tsq')
            tsq = np.fromfile(tsq_filename, dtype=tsq_dtype)
            self._tsq.append(tsq)
            
            rec_marker = tsq[tsq['code_type']==0x8801]['timestamp']
            global_t_start, global_t_stop = rec_marker
            self._global_t_start.append(global_t_start)
            self._global_t_stop.append(global_t_stop)
            

            #if there exists an external sortcode in ./sort/[sortname]/*.SortResult (generated after offline sortting)
            sortresult_filename = None
            if self.sortname is not '':
                try:
                    for file in os.listdir(os.path.join(path, 'sort', sortname)):
                        if file.endswith(".SortResult"):
                            sortresult_filename = os.path.join(path, 'sort', sortname, file)
                            
                            # get new sortcode
                            newsorcode = np.fromfile(sortresult_filename,'int8')[1024:]  # the first 1024 byte is file header
                            # update the sort code with the info from this file
                            tsq['sortcode'][1:-1]=newsorcode
                            # print('sortcode updated')
                            break
                except OSError:
                    pass
                except IOError:
                    pass
        
        #signal channels #'EVTYPE_STREAM' 33025
        signal_channels =[]
        self._sigs_data_buf = {seg_index:{} for seg_index in range(nb_segment)}
        self._sigs_index = {seg_index:{} for seg_index in range(nb_segment)}
        keep = info_channel_groups['TankEvType'] == 33025
        #TODO for the moment only the first grousp of channels i take
        # because different simpling rate
        for info in info_channel_groups[keep][2:3]:
        
            for c in range(info['NumChan']):
                chan_name = '{} {}'.format(info['StoreName'], c+1)
                chan_id = c+1
                units = 'V' #TODO this is not sur at all
                gain = 1.
                offset = 0.
                signal_channels.append((chan_name, chan_id, units, gain,offset))
                
                
                for seg_index, segment_name in enumerate(segment_names):
                    #get data index
                    tsq = self._tsq[seg_index]
                    
                    mask = (tsq['code_type']==33025) &\
                                (tsq['store_name']==info['StoreName']) &\
                                (tsq['channel_id']==chan_id)
                    data_index = tsq[mask].copy()
                    self._sigs_index[seg_index][chan_id] = data_index
                    
                    #data buffer test if SEV file exists otherwise TEV
                    path = os.path.join(self.dirname, segment_name)
                    sev_filename = os.path.join(path, tankname+'_'+segment_name+'_'+info['StoreName'].decode('ascii')+'_ch'+str(chan_id)+'.sev')
                    if os.path.exists(sev_filename):
                        data = np.memmap(sev_filename, mode='r', offset=0, dtype='uint8')
                    else:
                        data = self._tev_datas[seg_index]
                        assert data is not None, 'no TEV nor SEV'
                    #TODO chan_id here because it is not unique!!!!!!
                    self._sigs_data_buf[seg_index][chan_id] = data
        
        signal_channels = []
        signal_channels = np.array(signal_channels, dtype=_signal_channel_dtype)
        
        #TODO assert all signals have the same data_index.size for each segment
        if len(signal_channels)>0:
            chan_id0 = signal_channels['id'][0]
            data_index0 = self._sigs_index[0][chan_id0]
            self._sig_dtype = np.dtype(data_formats[data_index0['dataformat'][0]])
            self._sig_sampling_rate = float(data_index0['frequency'][0])
            self._sig_sample_per_chunk = info['NumPoints']
            self._sigs_lengths = []
            for seg_index, segment_name in enumerate(segment_names):
                data_index0 = self._sigs_index[seg_index][chan_id0]
                self._sigs_lengths.append(info['NumPoints'] * data_index0.size)


        #unit channels #'EVTYPE_SNIP'
        self.internal_unit_ids = {}
        self._waveforms_size = []
        self._waveforms_dtype = []
        unit_channels =[]
        keep = info_channel_groups['TankEvType'] == 33281
        for info in info_channel_groups[keep]:
            for c in range(info['NumChan']):
                chan_id = c+1
                #unit_ids is get only from the first segment
                #otherwise it would to long
                tsq = self._tsq[seg_index]
                mask = (tsq['code_type']==33281) &\
                            (tsq['store_name']==info['StoreName']) &\
                            (tsq['channel_id']==chan_id)
                unit_ids = np.unique(tsq[mask]['sortcode'])
                for unit_id in unit_ids:
                    unit_index = len(unit_channels)
                    self.internal_unit_ids[unit_index] = (info['StoreName'], chan_id, unit_id)
                    
                    unit_name = "ch{}#{}".format(chan_id, unit_id)
                    wf_units = 'V'
                    wf_gain = 1.
                    wf_offset = 0.
                    wf_left_sweep = info['NumPoints']//2
                    wf_sampling_rate = info['SampleFreq']
                    unit_channels.append((unit_name, '{}'.format(unit_id), wf_units, wf_gain, wf_offset, 
                                            wf_left_sweep, wf_sampling_rate))
                    
                    self._waveforms_size.append(info['NumPoints'])
                    self._waveforms_dtype.append(np.dtype(data_formats[info['DataFormat']]))
        
        unit_channels = np.array(unit_channels, dtype=_unit_channel_dtype)
        
        #signal channels #'EVTYPE_STRON'
        event_channels = []
        keep = info_channel_groups['TankEvType'] == 257
        for info in info_channel_groups[keep]:
            chan_name = info['StoreName']
            chan_id = 1
            event_channels.append((chan_name, chan_id, 'event'))
            
        event_channels = np.array(event_channels, dtype=_event_channel_dtype)
        
        #fille into header dict
        self.header = {}
        self.header['nb_block'] = 1
        self.header['nb_segment'] = [nb_segment]
        self.header['signal_channels'] = signal_channels
        self.header['unit_channels'] = unit_channels
        self.header['event_channels'] = event_channels
        
       # Annotations
        self._generate_minimal_annotations()
        #TODO annotations
        
    
    def _block_count(self):
        return 1
    
    def _segment_count(self, block_index):
        return self.header['nb_segment'][block_index]
    
    def _segment_t_start(self, block_index, seg_index):
        return 0. #TODO

    def _segment_t_stop(self, block_index, seg_index):
        return self._global_t_stop[seg_index] - self._global_t_start[seg_index]
    
    def _analogsignal_shape(self, block_index, seg_index):
        #TODO work only for one channel group
        return (self._sigs_lengths[seg_index], self.header['signal_channels'].size)
    
    def _analogsignal_sampling_rate(self):
        #TODO work only for one channel group
        return self._sig_sampling_rate

    def _get_analogsignal_chunk(self, block_index, seg_index,  i_start, i_stop, channel_indexes):
        if i_start is None:
            i_start = 0
        if i_stop is None:
            i_stop = self._sigs_lengths[seg_index]
        
        raw_signals = np.zeros((i_stop-i_start, len(channel_indexes)), dtype=self._sig_dtype)
        for c, channel_index in enumerate(channel_indexes):
            chan_header = self.header['signal_channels'][channel_index]
            chan_id = chan_header['id']
            
            data_index = self._sigs_index[seg_index][chan_id]
            data_buf = self._sigs_data_buf[seg_index][chan_id]
            
            #loop over data blocks and get chunks
            bl0 = i_start//self._sig_sample_per_chunk
            bl1 = int(np.ceil(i_stop/self._sig_sample_per_chunk))
            
            ind = 0
            for bl in range(bl0,  bl1):
                ind0 = data_index[bl]['offset']
                ind1 = ind0 + self._sig_sample_per_chunk*self._sig_dtype.itemsize
                data = data_buf[ind0:ind1].view(self._sig_dtype)
                
                if bl == bl1-1:
                    #right border
                    #be carfull that bl could be both bl0 and bl1!!
                    border = data.size - (i_stop % self._sig_sample_per_chunk)
                    data = data[:-border]
                if bl == bl0:
                    #left border
                    border = i_start%self._sig_sample_per_chunk
                    data = data[border:]
                
                raw_signals[ind:data.size+ind, c] = data
                ind += data.size
            
        return raw_signals

    def _get_mask(self, tsq, seg_index, code_type, store_name, chan_id, unit_id, t_start, t_stop):
        mask = (tsq['code_type']==code_type) & \
                    (tsq['store_name']==store_name) & \
                    (tsq['channel_id']==chan_id)
        
        if unit_id is not None:
            mask &= (tsq['sortcode']==unit_id)
        
        if t_start is not None:
            mask &= tsq['timestamp']>=(t_start+self._global_t_start[seg_index])
        
        if t_stop is not None:
            mask &= tsq['timestamp']<=(t_stop+self._global_t_start[seg_index])
        
        return mask
    
    def _spike_count(self,  block_index, seg_index, unit_index):
        store_name, chan_id, unit_id = self.internal_unit_ids[unit_index]
        tsq = self._tsq[seg_index]
        mask = self. _get_mask(tsq, seg_index, 33281, store_name, chan_id, unit_id, None, None)
        nb_spike = np.sum(mask)
        return nb_spike
    
    
    def _spike_timestamps(self,  block_index, seg_index, unit_index, t_start, t_stop):
        store_name, chan_id, unit_id = self.internal_unit_ids[unit_index]
        tsq = self._tsq[seg_index]
        mask = self. _get_mask(tsq, seg_index, 33281, store_name, chan_id, unit_id, t_start, t_stop)
        timestamps = tsq[mask]['timestamp']
        timestamps -= self._global_t_start[seg_index]
        return timestamps
    
    def _rescale_spike_timestamp(self, spike_timestamps, dtype):
        #already in s
        spike_times = spike_timestamps.astype(dtype)
        return spike_times

    def _spike_raw_waveforms(self, block_index, seg_index, unit_index, t_start, t_stop):
        store_name, chan_id, unit_id = self.internal_unit_ids[unit_index]
        tsq = self._tsq[seg_index]
        mask = self. _get_mask(tsq, seg_index, 33281, store_name, chan_id, unit_id, t_start, t_stop)
        nb_spike = np.sum(mask)
        
        data = self._tev_datas[seg_index]
        
        dt = self._waveforms_dtype[unit_index]
        nb_sample = self._waveforms_size[unit_index]
        waveforms = np.zeros((nb_spike, 1, nb_sample), dtype=dt)
        
        for i, e in enumerate(tsq[mask]):
            ind0 = e['offset']
            ind1 = ind0 +nb_sample*dt.itemsize
            waveforms[i, 0, :] = data[ind0:ind1].view(dt)
        
        return waveforms
    
    def _event_count(self, block_index, seg_index, event_channel_index):
        h = self.header['event_channels'][event_channel_index]
        store_name = h['name'].encode('ascii')
        tsq = self._tsq[seg_index]
        chan_id = 0
        mask = self. _get_mask(tsq, seg_index, 257, store_name, chan_id, None, None, None)
        nb_event = np.sum(mask)
        return nb_event
    
    def _event_timestamps(self,  block_index, seg_index, event_channel_index, t_start, t_stop):
        h = self.header['event_channels'][event_channel_index]
        store_name = h['name'].encode('ascii')
        tsq = self._tsq[seg_index]
        chan_id = 0
        mask = self. _get_mask(tsq, seg_index, 257, store_name, chan_id, None, None, None)
        
        #TODO one day transform event to epoch
        # with EVTYPE_STROFF=258
        
        timestamps = tsq[mask]['timestamp']
        timestamps -= self._global_t_start[seg_index]
        labels = tsq[mask]['offset'].astype('U')
        durations = None
        return timestamps, durations, labels
    
    
    def _rescale_event_timestamp(self, event_timestamps, dtype):
        #already in s
        ev_times = event_timestamps.astype(dtype)
        return ev_times


tbk_field_types = [
    ('StoreName', 'S4'),
    ('HeadName', 'S16'),
    ('Enabled', 'bool'),
    ('CircType', 'int'),
    ('NumChan', 'int'), 
    ('StrobeMode', 'int'),
    ('TankEvType', 'int32'),
    ('NumPoints', 'int'),
    ('DataFormat', 'int'),
    ('SampleFreq', 'float64'),
]

def read_tbk(tbk_filename):
    """
    Tbk contains some visible header in txt mode to describe
    channel group info.
    """
    with open(tbk_filename, mode='rb') as f:
        txt_header = f.read()
        
    infos = []
    for chan_grp_header in txt_header.split(b'[STOREHDRITEM]'):
        if chan_grp_header.startswith(b'[USERNOTEDELIMITER]'):
            break
        
        #parse into a dict
        info = OrderedDict()
        pattern = b'NAME=(\S+);TYPE=(\S+);VALUE=(\S+);'
        r = re.findall(pattern, chan_grp_header)
        for name, _type, value in r:
            info[name.decode('ascii')] = value
        infos.append(info)
    
    # and put into numpy
    info_channel_groups = np.zeros(len(infos), dtype=tbk_field_types)
    for i, info in enumerate(infos):
        for k, dt in tbk_field_types:
            v = np.dtype(dt).type(info[k])
            info_channel_groups[i][k] = v
    
    return info_channel_groups



tsq_dtype = [
    ('size','int32'),
    ('code_type','int32'), #('evtype','int32'),
    ('store_name','S4'),   #('code','S4'),
    ('channel_id','uint16'), #('channel','uint16'),
    ('sortcode','uint16'),
    ('timestamp','float64'),
    ('offset','int64'),
    ('dataformat','int32'),
    ('frequency','float32'),
]


tdt_code_types = {
    0: 'EVTYPE_UNKNOWN', 
    257: 'EVTYPE_STRON', # 0x101
    258: 'EVTYPE_STROFF', #0x102
    #~ 513: 'EVTYPE_SCALER', #0x201
    33025: 'EVTYPE_STREAM', #0x8101
    33281: 'EVTYPE_SNIP', #0x8201
    #~ 34817: 'EVTYPE_MARK', #0x8801
}

data_formats = {
        0 : 'float32',
        1 : 'int32',
        2 : 'int16',
        3 : 'int8',
        4 : 'float64',
        }

def is_tdtblock(blockpath):
    """
    A TDT block is a neo.Segment.
    
    """
    file_ext = list()
    if os.path.isdir(blockpath):
        for file in os.listdir( blockpath ):   # for every file, get extension, convert to lowercase and append
            file_ext.append( os.path.splitext( file )[1].lower() )

    file_ext = set(file_ext)
    tdt_ext  = set(['.tbk', '.tdx', '.tev', '.tsq'])
    if file_ext >= tdt_ext:    # if containing all the necessary files
        return True
    else:
        return False
